# AIMA GPU Orchestration Service

üöÄ **Phase 2.2: Job- und GPU-Orchestrierung** - Gestartet am 22.07.2025

Ein umfassender GPU-Orchestrierungsservice f√ºr die Verwaltung von KI-Workloads √ºber mehrere Cloud-Anbieter hinweg, einschlie√ülich RunPod, Vast.ai und AWS.

## üéØ √úberblick

Der AIMA GPU Orchestration Service bietet:

- **Job Queue Management**: Intelligente Warteschlangenverwaltung und Scheduling
- **Multi-Provider GPU Orchestration**: Unterst√ºtzung f√ºr RunPod, Vast.ai und AWS
- **Kostenoptimierung**: Automatische Anbieterauswahl basierend auf Kosten und Verf√ºgbarkeit
- **LLaVA & Llama Integration**: Spezialisierte Templates f√ºr LLaVA-1.6 (34B) und Llama 3.1 (70B)
- **Real-time Monitoring**: Prometheus-Metriken und Grafana-Dashboards
- **Auto-Scaling**: Automatische Skalierung basierend auf Workload

## üèóÔ∏è Architektur

### GPU Cluster Konfiguration
- **6x RTX 4090** (144GB VRAM gesamt)
- **4x GPUs** f√ºr LLaVA-1.6 (34B)
- **2x GPUs** f√ºr Llama 3.1 (70B)
- **Load Balancing** zwischen Instanzen

### Technische Komponenten
- **FastAPI** - REST API Framework
- **PostgreSQL** - Prim√§re Datenbank
- **Redis** - Caching und Session Management
- **RabbitMQ** - Message Queue f√ºr Job Processing
- **Kubernetes** - Container Orchestration
- **Terraform** - Infrastructure as Code
- **Prometheus & Grafana** - Monitoring und Metriken

## üöÄ Schnellstart

### Voraussetzungen

- Python 3.11+
- Docker & Docker Compose
- kubectl (f√ºr Kubernetes Integration)
- Terraform (f√ºr Infrastructure Management)

### Installation

1. **Repository klonen**
   ```bash
   git clone https://github.com/aima/gpu-orchestration.git
   cd gpu-orchestration
   ```

2. **Umgebungsvariablen konfigurieren**
   ```bash
   cp .env.example .env
   # Bearbeite .env mit deinen API-Schl√ºsseln
   ```

3. **Services mit Docker Compose starten**
   ```bash
   docker-compose up -d
   ```

4. **Datenbank initialisieren**
   ```bash
   docker-compose exec gpu-orchestration python start_service.py --init-db
   ```

### Lokale Entwicklung

1. **Virtuelle Umgebung erstellen**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # oder
   venv\Scripts\activate     # Windows
   ```

2. **Dependencies installieren**
   ```bash
   pip install -r requirements.txt
   ```

3. **Service starten**
   ```bash
   python start_service.py
   ```

## üìö API Dokumentation

Nach dem Start ist die API-Dokumentation verf√ºgbar unter:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Wichtige Endpoints

#### Job Management
- `POST /api/v1/jobs/submit` - Neuen Job einreichen
- `GET /api/v1/jobs/{job_id}` - Job-Status abrufen
- `GET /api/v1/jobs/` - Jobs auflisten
- `DELETE /api/v1/jobs/{job_id}` - Job abbrechen

#### GPU Instanzen
- `GET /api/v1/instances/` - Aktive Instanzen auflisten
- `GET /api/v1/instances/{instance_id}` - Instanz-Details
- `DELETE /api/v1/instances/{instance_id}` - Instanz beenden

#### Provider Management
- `GET /api/v1/providers/` - Verf√ºgbare Provider
- `GET /api/v1/providers/{provider}/pricing` - Preise abrufen
- `GET /api/v1/providers/{provider}/status` - Provider-Status

#### Monitoring
- `GET /health` - Service Health Check
- `GET /metrics` - Prometheus Metriken
- `GET /api/v1/monitoring/dashboard` - Dashboard-Daten

## üîß Konfiguration

### GPU Provider Setup

#### RunPod
1. Account erstellen auf [RunPod](https://www.runpod.io)
2. API-Schl√ºssel generieren in den User Settings
3. `RUNPOD_API_KEY` in `.env` setzen

#### Vast.ai
1. Account erstellen auf [Vast.ai](https://console.vast.ai)
2. API-Schl√ºssel in Account Settings generieren
3. `VAST_API_KEY` in `.env` setzen

#### AWS
1. IAM User mit EC2-Berechtigungen erstellen
2. Access Key und Secret Key generieren
3. `AWS_ACCESS_KEY_ID` und `AWS_SECRET_ACCESS_KEY` setzen

### Job Templates

Vordefinierte Templates f√ºr h√§ufige Anwendungsf√§lle:

#### LLaVA-1.6 34B Template
```json
{
  "name": "LLaVA-1.6 34B Analysis",
  "job_type": "llava",
  "config": {
    "model_name": "llava-v1.6-34b",
    "gpu_type": "RTX4090",
    "gpu_count": 4,
    "memory_gb": 96,
    "docker_image": "aima/llava:1.6-34b"
  }
}
```

#### Llama 3.1 70B Template
```json
{
  "name": "Llama 3.1 70B Text Generation",
  "job_type": "llama",
  "config": {
    "model_name": "llama-3.1-70b",
    "gpu_type": "RTX4090",
    "gpu_count": 2,
    "memory_gb": 48,
    "docker_image": "aima/llama:3.1-70b"
  }
}
```

## üìä Monitoring

### Grafana Dashboards
Zugriff auf Grafana: http://localhost:3000
- **Username**: admin
- **Password**: admin

Verf√ºgbare Dashboards:
- GPU Orchestration Overview
- Job Performance Metrics
- Provider Comparison
- Cost Analysis
- System Resources

### Prometheus Metriken
Zugriff auf Prometheus: http://localhost:9091

Wichtige Metriken:
- `gpu_jobs_total` - Gesamtanzahl Jobs
- `gpu_instances_active` - Aktive GPU-Instanzen
- `gpu_cost_hourly` - St√ºndliche Kosten
- `gpu_utilization_percent` - GPU-Auslastung

## üîí Sicherheit

### API-Authentifizierung
- JWT-Token basierte Authentifizierung
- Benutzer-spezifische Ressourcen-Quotas
- Rate Limiting f√ºr API-Endpoints

### Secrets Management
- Alle API-Schl√ºssel werden verschl√ºsselt gespeichert
- Umgebungsvariablen f√ºr sensible Daten
- Kubernetes Secrets f√ºr Production

## üß™ Testing

### Unit Tests
```bash
pytest tests/unit/
```

### Integration Tests
```bash
pytest tests/integration/
```

### Load Tests
```bash
pytest tests/load/
```

## üìà Performance

### Benchmarks
- **Job Submission**: < 100ms
- **Instance Creation**: 2-5 Minuten (abh√§ngig vom Provider)
- **API Response Time**: < 50ms (95th percentile)
- **Throughput**: 1000+ Jobs/Stunde

### Skalierung
- **Horizontal Scaling**: Mehrere Service-Instanzen
- **Auto-Scaling**: Basierend auf Queue-L√§nge
- **Load Balancing**: Nginx/HAProxy Integration

## üõ†Ô∏è Entwicklung

### Code-Struktur
```
app/
‚îú‚îÄ‚îÄ api/           # FastAPI Router
‚îú‚îÄ‚îÄ core/          # Konfiguration & Database
‚îú‚îÄ‚îÄ models/        # SQLAlchemy Models
‚îú‚îÄ‚îÄ providers/     # GPU Provider Implementierungen
‚îî‚îÄ‚îÄ services/      # Business Logic
```

### Beitragen
1. Fork das Repository
2. Feature Branch erstellen (`git checkout -b feature/amazing-feature`)
3. √Ñnderungen committen (`git commit -m 'Add amazing feature'`)
4. Branch pushen (`git push origin feature/amazing-feature`)
5. Pull Request erstellen

### Code Style
- **Black** f√ºr Code-Formatierung
- **isort** f√ºr Import-Sortierung
- **flake8** f√ºr Linting
- **mypy** f√ºr Type Checking

```bash
# Code formatieren
black app/
isort app/

# Linting
flake8 app/
mypy app/
```

## üìã Roadmap

### Phase 2.2 (Aktuell) - Q3 2025
- [x] Job Management Module
- [x] GPU Orchestration Module
- [x] RunPod Integration
- [ ] Vast.ai Integration
- [ ] LLaVA-1.6 Container Images
- [ ] Load Balancing Implementation

### Phase 2.3 - Q4 2025
- [ ] AWS Integration
- [ ] Advanced Cost Optimization
- [ ] Multi-Region Support
- [ ] Enhanced Monitoring

### Phase 3.0 - Q1 2026
- [ ] Machine Learning Scheduling
- [ ] Predictive Scaling
- [ ] Advanced Analytics
- [ ] Multi-Tenant Support

## üêõ Troubleshooting

### H√§ufige Probleme

#### Service startet nicht
```bash
# Logs √ºberpr√ºfen
docker-compose logs gpu-orchestration

# Datenbank-Verbindung testen
docker-compose exec postgres psql -U postgres -d gpu_orchestration
```

#### GPU Provider Fehler
```bash
# Provider-Status √ºberpr√ºfen
curl http://localhost:8000/api/v1/providers/runpod/status

# API-Schl√ºssel validieren
curl -H "Authorization: Bearer $RUNPOD_API_KEY" https://api.runpod.ai/graphql
```

#### Performance Probleme
```bash
# System-Metriken √ºberpr√ºfen
curl http://localhost:8000/api/v1/monitoring/metrics/system

# Datenbankverbindungen
docker-compose exec postgres psql -U postgres -c "SELECT * FROM pg_stat_activity;"
```

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/aima/gpu-orchestration/issues)
- **Dokumentation**: [Wiki](https://github.com/aima/gpu-orchestration/wiki)
- **Email**: team@aima.ai
- **Slack**: #gpu-orchestration

## üìÑ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe [LICENSE](LICENSE) f√ºr Details.

## üôè Danksagungen

- RunPod Team f√ºr die ausgezeichnete GPU-Cloud-Plattform
- Vast.ai f√ºr kosteng√ºnstige GPU-Ressourcen
- FastAPI Community f√ºr das gro√üartige Framework
- AIMA Team f√ºr die kontinuierliche Unterst√ºtzung

---

**AIMA GPU Orchestration Service** - Powering the Future of AI Workloads üöÄ